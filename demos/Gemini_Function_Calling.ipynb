{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oluseysco/Gemini_Practice/blob/main/demos/Gemini_Function_Calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini API: Function Calling"
      ],
      "metadata": {
        "id": "QVriLoUiRZmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "1PEbg4MtTTiG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wko9cvMiNwme",
        "outputId": "f4e32274-4e92-40e6-f8b9-1a57db8d3884",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.2/164.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.3/718.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U -q google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "fvYqqsZnOILn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "ygVKV-nxOK60"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single Function\n"
      ],
      "metadata": {
        "id": "wsMUFmUaTZzt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gemini has the ability to call user-defined functions. Let's take a look at how exactly to do this. Firstly, let us define some functions relating to a hypothetical Italian restaurant located in Berkeley."
      ],
      "metadata": {
        "id": "cLIDhRAfTgfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_full_menu(service: str):\n",
        "    \"\"\"List all items on the menu of Gemini's Trattoria for the given service.\n",
        "\n",
        "    Args:\n",
        "        name: The type of service, lunch or dinner.\n",
        "    \"\"\"\n",
        "    return [\"Chicken Caesar Salad\", \"Margherita Pizza\", \"Spaghetti and Meatballs\", \"Eggplant Parmesan\"]\n",
        "\n",
        "\n",
        "def find_vegetarian_items(items: list[str]):\n",
        "    \"\"\"List all dishes in items that are vegetarian.\n",
        "\n",
        "    Args:\n",
        "        items: A list of dinner dishes.\n",
        "    \"\"\"\n",
        "    return [\"Margherita Pizza\", \"Eggplant Parmesan\"]\n",
        "\n",
        "def enter_restaurant():\n",
        "    \"\"\"You enter Gemini's Trattoria, moving the creaky door.\"\"\"\n",
        "    print(\"The door swings open, making a loud noise.\")\n",
        "    return True\n",
        "\n",
        "functions = {\"get_full_menu\": get_full_menu,\n",
        "             \"find_vegetarian_items\": find_vegetarian_items,\n",
        "             \"enter_restaurant\": enter_restaurant}"
      ],
      "metadata": {
        "id": "IIe-cXLHOWoo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After this, we go ahead and define our Gemini model. Notice how we include the argument for tools, which tells the model which functions it has available to use. We create a chat and set automatic function calling to True, which we will touch on later."
      ],
      "metadata": {
        "id": "qQDJ_k4qfhb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.5-flash\", tools=functions.values()\n",
        ")\n",
        "\n",
        "chat = model.start_chat(enable_automatic_function_calling=True)"
      ],
      "metadata": {
        "id": "V8stPgRtOaEN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we go ahead and send a prompt that requires the model to call our user-defined functions."
      ],
      "metadata": {
        "id": "hSR_d9Mofu_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\n",
        "    \"What items are on Gemini's Trattoria's dinner menu?\"\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "enDA7oh7OeGO",
        "outputId": "647289b8-7ddb-4d39-c5c0-1d618ca36d82"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dinner menu at Gemini's Trattoria has the following items: Chicken Caesar Salad, Margherita Pizza, Spaghetti and Meatballs, and Eggplant Parmesan. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see in the chat history, the model initially sends back a function call, to which we automatically respond, which then leads to the final model output."
      ],
      "metadata": {
        "id": "C7miJvuiCLJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for content in chat.history:\n",
        "    print(content.role, \"->\", [type(part).to_dict(part) for part in content.parts])\n",
        "    print(\"-\" * 180)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mZCERSwOhuh",
        "outputId": "91323b2c-c7e7-45eb-b269-957ef8ffc074"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user -> [{'text': \"What items are on Gemini's Trattoria's dinner menu?\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'function_call': {'name': 'get_full_menu', 'args': {'service': 'dinner'}}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "user -> [{'function_response': {'name': 'get_full_menu', 'response': {'result': ['Chicken Caesar Salad', 'Margherita Pizza', 'Spaghetti and Meatballs', 'Eggplant Parmesan']}}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'text': \"The dinner menu at Gemini's Trattoria has the following items: Chicken Caesar Salad, Margherita Pizza, Spaghetti and Meatballs, and Eggplant Parmesan. \\n\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Behind The Scenes"
      ],
      "metadata": {
        "id": "AiGwwQs6TkiH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In general, the processes goes as follows:\n",
        "1. The user submits a query to the model.\n",
        "2. The model responds with a function call.\n",
        "3. The user runs the function and returns the result of the function.\n",
        "4. Now, the model will either go back to Step 2 or output a final response, as seen above.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://video.udacity-data.com/topher/2024/June/66749652_function_calling/function_calling.jpeg\" width=\"500\"/>\n",
        "</div>"
      ],
      "metadata": {
        "id": "mQ1gZGNyTrPr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see this step-by-step in action by running the previous example with manual function calling, by setting the automatic function calling argument to False."
      ],
      "metadata": {
        "id": "in9bG0g7kXn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(enable_automatic_function_calling=False)\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"What items are on Gemini's Trattoria's dinner menu?\"\n",
        ")\n",
        "\n",
        "part = response.candidates[0].content.parts[0]\n",
        "part"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "yp-3ixnGkuHr",
        "outputId": "626613ae-210b-43c0-f9ab-675ddabe647a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "function_call {\n",
              "  name: \"get_full_menu\"\n",
              "  args {\n",
              "    fields {\n",
              "      key: \"service\"\n",
              "      value {\n",
              "        string_value: \"dinner\"\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After this, we can reply to the model as specified in Step 3, using the functions dictionary we made earlier."
      ],
      "metadata": {
        "id": "5kYKYoDElpzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.ai.generativelanguage as glm\n",
        "from google.protobuf.struct_pb2 import Struct\n",
        "\n",
        "# Put the result in a protobuf Struct\n",
        "s = Struct()\n",
        "result = functions[part.function_call.name](**part.function_call.args)\n",
        "s.update({\"result\": result})\n",
        "\n",
        "function_response = glm.Part(\n",
        "    function_response=glm.FunctionResponse(name=\"get_full_menu\", response=s)\n",
        ")\n",
        "\n",
        "# Generate the next response\n",
        "response = chat.send_message(function_response)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "bCD47Ry7lpKx",
        "outputId": "75c44e5d-c2f0-4b89-f033-398ab19ce472"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dinner menu has: Chicken Caesar Salad, Margherita Pizza, Spaghetti and Meatballs, Eggplant Parmesan. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Function Calls"
      ],
      "metadata": {
        "id": "S3q5nWqyoj6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model can also call multiple functions in a row, either at the same time or one after the other, as we see in both cases below."
      ],
      "metadata": {
        "id": "Iug5VBZ5kWw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(enable_automatic_function_calling=True)\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"What items on Gemini's Trattoria's dinner menu are vegetarian?\"\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "S7_gRd2QQCId",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b6e5de01-61bb-4bb7-db66-97217e6e25b7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vegetarian options on Gemini's Trattoria's dinner menu are Margherita Pizza and Eggplant Parmesan. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for content in chat.history:\n",
        "    print(content.role, \"->\", [type(part).to_dict(part) for part in content.parts])\n",
        "    print(\"-\" * 180)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJNvCH77jaYf",
        "outputId": "43bd3496-d5e7-4f77-f3a4-cfd1e1ebb66a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user -> [{'text': \"What items on Gemini's Trattoria's dinner menu are vegetarian?\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'function_call': {'name': 'get_full_menu', 'args': {'service': 'dinner'}}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "user -> [{'function_response': {'name': 'get_full_menu', 'response': {'result': ['Chicken Caesar Salad', 'Margherita Pizza', 'Spaghetti and Meatballs', 'Eggplant Parmesan']}}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'function_call': {'name': 'find_vegetarian_items', 'args': {'items': ['Chicken Caesar Salad', 'Margherita Pizza', 'Spaghetti and Meatballs', 'Eggplant Parmesan']}}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "user -> [{'function_response': {'name': 'find_vegetarian_items', 'response': {'result': ['Margherita Pizza', 'Eggplant Parmesan']}}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'text': \"The vegetarian options on Gemini's Trattoria's dinner menu are Margherita Pizza and Eggplant Parmesan. \\n\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(enable_automatic_function_calling=True)\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"Your are standing outside of Gemini's Trattoria. Enter the restaurant and read out the items on the menu.\"\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "9WqeUW_zoadm",
        "outputId": "fd5e2c7b-ce6f-48ae-c32e-3b6d95600741"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The door swings open, making a loud noise.\n",
            "I push open the door and step inside. It's a little noisy, but it's a cozy, old-fashioned trattoria.  The menu reads: \n",
            "\n",
            "\"Tonight's dinner specials are: Chicken Caesar Salad, Margherita Pizza, Spaghetti and Meatballs, and Eggplant Parmesan.\" \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for content in chat.history:\n",
        "    print(content.role, \"->\", [type(part).to_dict(part) for part in content.parts])\n",
        "    print(\"-\" * 180)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaP34mbbpUyx",
        "outputId": "8407a84b-18c4-4297-8205-c474dbbd01f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user -> [{'text': \"Your are standing outside of Gemini's Trattoria. Enter the restaurant and read out the items on the menu.\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'function_call': {'name': 'enter_restaurant', 'args': {}}}, {'function_call': {'name': 'get_full_menu', 'args': {'service': 'dinner'}}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "user -> [{'function_response': {'name': 'enter_restaurant', 'response': {'result': True}}}, {'function_response': {'name': 'get_full_menu', 'response': {'result': ['Chicken Caesar Salad', 'Margherita Pizza', 'Spaghetti and Meatballs', 'Eggplant Parmesan']}}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'text': \"Welcome to Gemini's Trattoria! Tonight we have Chicken Caesar Salad, Margherita Pizza, Spaghetti and Meatballs, and Eggplant Parmesan. \\n\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Calling Config"
      ],
      "metadata": {
        "id": "5hAZc4iCp20w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a function calling config lets us control how the Gemini API acts when tools have been specified. Let us use the same previous example and see what happens in each of three cases."
      ],
      "metadata": {
        "id": "bXF1laiBqVkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.generativeai.types import content_types\n",
        "from collections.abc import Iterable\n",
        "\n",
        "\n",
        "def tool_config_from_mode(mode: str, fns: Iterable[str] = ()):\n",
        "    \"\"\"Create a tool config with the specified function calling mode.\"\"\"\n",
        "    return content_types.to_tool_config(\n",
        "        {\"function_calling_config\": {\"mode\": mode, \"allowed_function_names\": fns}}\n",
        "    )"
      ],
      "metadata": {
        "id": "MS_lpBLRpuli"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we use the NONE mode, which tells the model to not make any function calls. In this example, the model knows about the get_full_menu function but is unable to use it."
      ],
      "metadata": {
        "id": "2MkyISN3rCVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tool_config = tool_config_from_mode(\"none\")\n",
        "chat = model.start_chat(enable_automatic_function_calling=True)\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"What items on Gemini's Trattoria's dinner menu are vegetarian?\", tool_config=tool_config\n",
        ")\n",
        "\n",
        "for content in chat.history:\n",
        "    print(content.role, \"->\", [type(part).to_dict(part) for part in content.parts])\n",
        "    print(\"-\" * 180)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "IOnPq6zVrMCq",
        "outputId": "4e82b8c2-7dd5-4659-8692-eac80613de0c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user -> [{'text': \"What items on Gemini's Trattoria's dinner menu are vegetarian?\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'text': \"Please provide me with the dinner menu of Gemini's Trattoria so I can identify the vegetarian items. \\n\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AUTO mode lets the model decide whether to reply with text or to call specific functions. In this example, we see that the model calls a function to get all menu items but is able to reason on its own on which items are pasta dishes."
      ],
      "metadata": {
        "id": "QIDmVQUfrqh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tool_config = tool_config_from_mode(\"auto\")\n",
        "chat = model.start_chat(enable_automatic_function_calling=True)\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"What items on Gemini's Trattoria's dinner menu are pasta dishes?\", tool_config=tool_config\n",
        ")\n",
        "\n",
        "for content in chat.history:\n",
        "    print(content.role, \"->\", [type(part).to_dict(part) for part in content.parts])\n",
        "    print(\"-\" * 180)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "B3kOMeGirZAp",
        "outputId": "bf4d4bf7-891b-48d8-d9f6-5d997b7fe601"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user -> [{'text': \"What items on Gemini's Trattoria's dinner menu are pasta dishes?\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'function_call': {'name': 'get_full_menu', 'args': {'service': 'dinner'}}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "user -> [{'function_response': {'name': 'get_full_menu', 'response': {'result': ['Chicken Caesar Salad', 'Margherita Pizza', 'Spaghetti and Meatballs', 'Eggplant Parmesan']}}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'text': \"The dinner menu at Gemini's Trattoria includes Spaghetti and Meatballs as a pasta dish. \\n\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, ANY mode forces the model to make function calls, as seen in the below example. We decide to switch over to the Gemini 1.5 Pro model to achieve the intended behavior."
      ],
      "metadata": {
        "id": "jMwHF05_sTW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.5-pro\", tools=functions.values()\n",
        ")\n",
        "\n",
        "tool_config = tool_config_from_mode(\"any\")\n",
        "chat = model.start_chat()\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"Enter Gemini's Trattoria.\", tool_config=tool_config\n",
        ")\n",
        "\n",
        "for content in chat.history:\n",
        "    print(content.role, \"->\", [type(part).to_dict(part) for part in content.parts])\n",
        "    print(\"-\" * 180)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "5rn0Xoi6ryDv",
        "outputId": "8a220d74-d41c-4597-866f-e3d20ba52a97"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user -> [{'text': \"Enter Gemini's Trattoria.\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'function_call': {'name': 'enter_restaurant', 'args': {}}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By setting allowed_function_names, the model will only choose from those functions. If it is not set, all of the functions in tools are candidates for function calling. In the below example, since we are in ANY mode, the model is forced to use a function, even though it is not necessarily the best option."
      ],
      "metadata": {
        "id": "_ribpz_fszjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tool_config = tool_config_from_mode(\"any\", [\"get_full_menu\"])\n",
        "chat = model.start_chat()\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"Enter Gemini's Trattoria.\", tool_config=tool_config\n",
        ")\n",
        "\n",
        "for content in chat.history:\n",
        "    print(content.role, \"->\", [type(part).to_dict(part) for part in content.parts])\n",
        "    print(\"-\" * 180)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "Z_lU1Xntu9ps",
        "outputId": "663cf6d8-7c24-439e-9858-e6ecd111316a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user -> [{'text': \"Enter Gemini's Trattoria.\"}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "model -> [{'function_call': {'name': 'get_full_menu', 'args': {'service': 'lunch'}}}]\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vd2ALTSCxA47"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}