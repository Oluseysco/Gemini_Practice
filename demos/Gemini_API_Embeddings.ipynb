{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6fcccef0",
      "metadata": {
        "id": "6fcccef0"
      },
      "source": [
        "# Gemini API: Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4aaf6c79",
      "metadata": {
        "id": "4aaf6c79"
      },
      "source": [
        "### Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8da4be14",
      "metadata": {
        "id": "8da4be14",
        "outputId": "eb863e6d-ec02-42d0-cea2-119aa00681b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.2/164.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.3/718.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U -q google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f743db17",
      "metadata": {
        "id": "f743db17"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e21f7cf",
      "metadata": {
        "id": "2e21f7cf"
      },
      "source": [
        "### Configuring API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cf35718f",
      "metadata": {
        "id": "cf35718f"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d8f069e",
      "metadata": {
        "id": "1d8f069e"
      },
      "source": [
        "# Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c389fe13",
      "metadata": {
        "id": "c389fe13"
      },
      "source": [
        "An **embedding** is a list of decimal point numbers that represent the meaning of a\n",
        "word/sentence/paragraph.\n",
        "A quantity of these numbers represent *dimensionality* of embeddings.\n",
        "\n",
        "Embeddings can be used in document search, anomaly detection, text classification, and many other tasks!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88c1f5dd",
      "metadata": {
        "id": "88c1f5dd"
      },
      "source": [
        "### Generating embeddings\n",
        "\n",
        "To generate embeddings for a given data, use `embed_content` method and pass in which `model` to use and what `content` to convert:\n",
        "\n",
        "- `model`: Required. Must be either `models/text-embedding-004` or `models/embedding-001`.\n",
        "\n",
        "- `content`: Required. The data to embed.\n",
        "\n",
        "- `output_dimensionality`: Optional. Reduced dimension for the output embedding. If set, excessive values in the output embedding are truncated from the end. This is supported by `models/text-embedding-004`, but cannot be specified in `models/embedding-001`.\n",
        "\n",
        "- `task_type`: Optional. The task type for which the embeddings will be used.\n",
        "\n",
        "- `title`: Optional. You should only set this parameter if your task type is `retrieval_document` (or `document`).\n",
        "\n",
        "(The latter three will be explored later.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc58e9f0",
      "metadata": {
        "id": "fc58e9f0"
      },
      "source": [
        "Here, we will use `models/text-embedding-004` to generate text embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4d8f5e9a",
      "metadata": {
        "id": "4d8f5e9a"
      },
      "outputs": [],
      "source": [
        "data = 'Hi there, this is Gemini tutorial!'\n",
        "\n",
        "embed_data = genai.embed_content(\n",
        "    model='models/text-embedding-004',\n",
        "    content=data\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3d4abff",
      "metadata": {
        "id": "a3d4abff"
      },
      "source": [
        "Since embeddings can have large dimensionality (i.e. length), we will output only first 10 values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8aeff0fe",
      "metadata": {
        "id": "8aeff0fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10d57a21-44ec-45bf-c7f1-67bbb6d05236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.058438968, 0.00044316906, -0.009973634, -0.016529616, 0.041487474, -0.013944049, 0.080064304, 0.055516902, -0.03406745, 0.046189807]\n"
          ]
        }
      ],
      "source": [
        "print(embed_data['embedding'][:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffe2153c",
      "metadata": {
        "id": "ffe2153c"
      },
      "source": [
        "By default, the embeddings have dimensionality of 768:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fedc8c95",
      "metadata": {
        "id": "fedc8c95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57b50301-5996-4b2e-9bc0-33b775c59d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "768\n"
          ]
        }
      ],
      "source": [
        "print(len(embed_data['embedding']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87c2010e",
      "metadata": {
        "id": "87c2010e"
      },
      "source": [
        "Instead of a single string values, we can also pass in a **batch** of data (i.e. a list of strings):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2e79c974",
      "metadata": {
        "id": "2e79c974"
      },
      "outputs": [],
      "source": [
        "data = [\n",
        "    'What is the tuition at UC Berkeley?',\n",
        "    'Name top 10 books about machine learning.',\n",
        "    'How to stop procrastinating?'\n",
        "]\n",
        "\n",
        "embed_data = genai.embed_content(\n",
        "    model='models/text-embedding-004',\n",
        "    content=data\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "196ddc08",
      "metadata": {
        "id": "196ddc08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "155fa1ce-72e9-4b74-8634-ee9c431174ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.05558104, 0.066228844, -0.0832767, -0.0021693057, 0.027031252, 0.0060264543, 0.027830552, -0.017377941, -0.05279287, 0.035122644]\n",
            "[0.017529475, -0.026426788, 0.0011475749, -0.022670645, -0.03672292, 0.009089399, -0.021839937, 0.022415882, -0.021802153, -0.027643519]\n",
            "[0.003983932, -0.026754132, 0.061292212, -0.013258428, -0.02447549, 0.04371135, -0.00851315, 0.012199542, 0.02470629, -0.012365352]\n"
          ]
        }
      ],
      "source": [
        "for embedding in embed_data['embedding']:\n",
        "    print(embedding[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "475e5486",
      "metadata": {
        "id": "475e5486"
      },
      "source": [
        "This allows us to use a single API call more efficiently (instead of calling multiple times)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82fee2c4",
      "metadata": {
        "id": "82fee2c4"
      },
      "source": [
        "### Truncating embeddings\n",
        "\n",
        "To reduce dimensionality of embeddings, we can specify it with `output_dimensionality` argument:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e7e32b6a",
      "metadata": {
        "id": "e7e32b6a"
      },
      "outputs": [],
      "source": [
        "embed_data = genai.embed_content(\n",
        "    model='models/text-embedding-004',\n",
        "    content='Below is how you truncate data!',\n",
        "    output_dimensionality=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2aebbd6",
      "metadata": {
        "id": "a2aebbd6"
      },
      "source": [
        "Now, the dimensionality of the output is restricted by 10:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ff18af6c",
      "metadata": {
        "id": "ff18af6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f57251e-9e77-4387-87ec-ee3c2a7feab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ],
      "source": [
        "print(len(embed_data['embedding']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29ca67db",
      "metadata": {
        "id": "29ca67db"
      },
      "source": [
        "### Specifying embeddings\n",
        "\n",
        "Since there are many different tasks where embeddings are used, you can refine them specifying for which one of the following `task_type`'s you are using embeddings for:\n",
        "\n",
        "- `unspecified`: If you do not set the value, it will default to `retrieval_query`.\n",
        "\n",
        "- `retrieval_query` (or `query`): The given text is a query in a search/retrieval setting.\n",
        "\n",
        "- `retrieval_document` (or `document`): The given text is a document from a corpus being searched. Optionally, also set the `title` parameter with the title of the document.\n",
        "\n",
        "- `semantic_similarity` (or `similarity`): The given text will be used for  Semantic Textual Similarity (STS).\n",
        "\n",
        "- `classification`: The given text will be classified.\n",
        "\n",
        "- `clustering`: The embeddings will be used for clustering.\n",
        "\n",
        "- `question_answering`: The given text will be used for question answering.\n",
        "\n",
        "- `fact_verification`: The given text will be used for fact verification."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28bd5e27",
      "metadata": {
        "id": "28bd5e27"
      },
      "source": [
        "Depending on the `task_type`, embeddings differ:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d400c506",
      "metadata": {
        "id": "d400c506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "7c6b63c5-58db-4c2d-c641-b7fc08427351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.044086624, -0.017505981, -0.014579227, 0.013675352, -0.008016501, 0.025225215, -0.035069168, 0.034015447, 0.037304174, 0.007439849]\n",
            "[-0.023972979, -0.019189887, -0.0222573, -0.012185102, 0.019129641, 0.035173632, -0.012367243, 0.016283926, 0.022629406, 0.014976865]\n"
          ]
        }
      ],
      "source": [
        "data = 'Finally touching the grass!'\n",
        "\n",
        "embed_data_1 = genai.embed_content(\n",
        "    model='models/text-embedding-004',\n",
        "    content=data\n",
        "    # no `task_type` specification; defaults to `retrieval_query`\n",
        ")\n",
        "\n",
        "embed_data_2 = genai.embed_content(\n",
        "    model='models/text-embedding-004',\n",
        "    content=data,\n",
        "    task_type='retrieval_document'\n",
        ")\n",
        "\n",
        "print(embed_data_1['embedding'][:10])\n",
        "print(embed_data_2['embedding'][:10])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}